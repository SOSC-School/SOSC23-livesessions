{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8108b3b-f2e2-4f9a-a4b8-9aac023d5f68",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Project - Day 4 - MLFlow evaluate and fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100da3d3-0b0f-4486-b0bf-b8e44bddd84e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Set parameters\n",
    "The cell below has been already tagged as `parameters`. So use it to include any papermill parameter you think it would be useful to change from at MLFlow runtime. (e.g. the location of models trained in the previous step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba0d710-2084-45ac-9500-02ebbcf93377",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "model_run_uri = \"dummy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013d7070-250e-431a-85e9-2f759548a188",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Loading libraries, data and model\n",
    "\n",
    "### Loading libraries and model from MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cce2eb6c-defc-497b-8b38-714607840575",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 09:57:23.042088: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:1095: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dciangot-mlflow.131.154.99.220.myip.cloud.infn.it'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "## We will be using Numpy, Pyplot and Tensorflow as our scientific tool box\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "## BytesIO for defining in-memory file-like objects\n",
    "from io import BytesIO\n",
    "\n",
    "## Dask and in particular dask array for defining OOM pipelines\n",
    "import dask\n",
    "import dask.array as da\n",
    "\n",
    "## Progress bars\n",
    "from tqdm import tqdm\n",
    "\n",
    "import mlflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac14455-6a4b-4ada-8adc-ec01f91ffa82",
   "metadata": {},
   "source": [
    "### Reproduce the final result plot based on the new model trained from the pipeline\n",
    "\n",
    "You should now be able to reproduce the steps of the Day-3 model deployment and adapt it to the MLFlow pipeline:\n",
    "\n",
    "- load the model from the artifact location of the previous step\n",
    "  - little help: `mlflow.artifacts.download_artifacts(artifact_uri=model_run_uri, dst_path=\"./models\")`\n",
    "- evaluate and fit the results, storing the plot as MLFlow artifacts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c764ef",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4790bb92",
   "metadata": {},
   "source": [
    "## SOLUTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af61233-12ee-461a-9e9b-7bad3fdf778f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://pandora.infn.it/public/cdf340/dl/soscdata.zip\n",
    "! mkdir -p input && cd input && unzip ../soscdata.zip\n",
    "\n",
    "object_names = []\n",
    "with open('object_list.csv\"') as f:\n",
    "    object_names = [x.strip(\"\\n\") for x in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1519c030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_npz_from_minio(object_name):\n",
    "  \"\"\"Load an object from Minio into a numpy array\"\"\"\n",
    "  return np.load(\"input/\"+object_name)\n",
    "\n",
    "\n",
    "def inspect_np(np_file):\n",
    "    \"\"\"Display key, shape and dtype of the arrays in a npz file\"\"\"\n",
    "    keys = np_file.keys()\n",
    "    print (\"Keys in file: \", \", \".join(keys))\n",
    "    for key in keys:\n",
    "        array = np_file[key]\n",
    "        print (\n",
    "            f\" - {key:<15s}\"\n",
    "            f\"   shape: {str(array.shape):<20s}\"\n",
    "            f\"   dtype: {array.dtype}\"\n",
    "          )\n",
    "\n",
    "npz_file = load_npz_from_minio(object_names[-1])\n",
    "print(npz_file)\n",
    "inspect_np(npz_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4b301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def load_array_from_minio(object_name, npz_key):\n",
    "    \"\"\"Load an array identified by npz_key from an npz file in Minio\"\"\"\n",
    "    npz = load_npz_from_minio(object_name)\n",
    "    return npz[npz_key] \n",
    "\n",
    "delayed_images = [\n",
    "    da.from_delayed(\n",
    "        load_array_from_minio(obj, 'image'),\n",
    "        shape=(10, 128, 128),\n",
    "        dtype=np.float64\n",
    "    )\n",
    "    for obj in object_names\n",
    "]\n",
    "\n",
    "images = da.concatenate(delayed_images)\n",
    "\n",
    "\n",
    "### \n",
    "delayed_tstamps = [\n",
    "    da.from_delayed(\n",
    "        load_array_from_minio(obj, 'tstamp'),\n",
    "        shape=(10,),\n",
    "        dtype=np.float64\n",
    "    )\n",
    "    for obj in object_names\n",
    "]\n",
    "\n",
    "tstamps = da.concatenate(delayed_tstamps)\n",
    "\n",
    "display(images)\n",
    "display(tstamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898bcead",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = mlflow.artifacts.download_artifacts(artifact_uri=model_run_uri, dst_path=\"./models\")\n",
    "classifier = tf.keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a198f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rechunk the image\n",
    "rechunked_images = images.rechunk((1000, -1, -1))\n",
    "\n",
    "## Evaluate the CNN model on the batches and concatenate the outputs\n",
    "predictions = np.concatenate([\n",
    "    classifier.predict_on_batch(x).flatten()\n",
    "    for x in tqdm(rechunked_images.blocks, total=rechunked_images.numblocks[0])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bf6cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_timestamp_histogram(\n",
    "    timestamps, \n",
    "    predictions,\n",
    "    threshold,\n",
    "    bin_width=1,\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates a histogram of the selected events in hourly bins.\n",
    "\n",
    "    Arguments:\n",
    "     - timestamps:  dask array of type np.datetime64\n",
    "     - predictions: numpy array of the classifier response with the same \n",
    "                    shape as timestamps\n",
    "     - threshold:   float, threshold in range [0,1] defining the minimum\n",
    "                    classifier's response to select a candidate event as NR\n",
    "     - bin_width:   float, approximate dimension of a bin in hours, default: 0.1\n",
    "\n",
    "    Returns:\n",
    "     - a tuple of 1D arrays (time_in_hours, number_of_selected_events)\n",
    "    \"\"\"\n",
    "    ## Obtain the timestamps as a numpy array\n",
    "    np_tstamps = timestamps.compute()\n",
    "\n",
    "    ## Retrieve the first timestmp as \"START\"\n",
    "    t0 = np_tstamps[0]\n",
    "\n",
    "    ## Select only the timestamps associated to a positive response\n",
    "    ## of the CNN classifier\n",
    "    t = np_tstamps[predictions > threshold]\n",
    "\n",
    "    ## Convert the timestamp in a number of hours since START\n",
    "    minutes_since_start = (t-t0)/np.timedelta64(1, 'm')\n",
    "\n",
    "    ## Compute the end of the time span as LATEST\n",
    "    tot_minutes = minutes_since_start.max()\n",
    "\n",
    "    ## Compute the number of bins as the first integer exceeding \n",
    "    ## the total number of hours divided per the width of each bin\n",
    "    bins = int(np.ceil(tot_minutes / bin_width))\n",
    "\n",
    "    ## Fill a histogram of \"hours since start\"\n",
    "    n_selected_events, boundaries = np.histogram(minutes_since_start, bins=bins)\n",
    "\n",
    "    ## Given the boundaries obtained from the histogram, compute the \n",
    "    ## center of each bin\n",
    "    time_in_minutes = 0.5 * (boundaries[1:] + boundaries[:-1])\n",
    "\n",
    "    ## Return the tuple with the center of the bin and the number of selected\n",
    "    ## events falling in that bin\n",
    "    return time_in_minutes, n_selected_events\n",
    "\n",
    "##############\n",
    "## Retrieve the histogram of counts for events more likely to be due to \n",
    "## nuclear recoil\n",
    "t, counts = make_timestamp_histogram(tstamps, predictions, 0.9)\n",
    "\n",
    "## Assuming Poissonian distribution of the contents, assess the uncertainty \n",
    "## on the counts\n",
    "error = np.sqrt(counts)\n",
    "\n",
    "## Plot the histogram\n",
    "plt.figure(figsize=(12,3))\n",
    "plt.xlabel(\"Time [m]\")\n",
    "plt.ylabel(\"Selected events\")\n",
    "plt.errorbar (t, counts, error, fmt='ko')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
